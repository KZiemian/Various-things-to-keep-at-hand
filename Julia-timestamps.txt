_Computing derivatives for chaotic and hybrid systems_, Frank Schäfer, [https://www.youtube.com/watch?v=iWyWro7T2to](https://www.youtube.com/watch?v=iWyWro7T2to)

Contents
00:00 Welcome!
01:23 Ordinary differential equations and sensitivity analysis (SA)
02:12 Problems with conventional methods when applied to chaotic systems
02:33 Short overview of sensitivity analysis
03:54 Introduction to chaotic systems
05:29 Methods for quantification of uncertanity in chaotic systems
06:24 Conventional SA and automatic differentiation (AD) aren't working properly in such systems
09:35 Shadowing lemma and shadowing methods
11:05 Replacing initial value problem by optimisation problem like least-squares problem
11:41 More refined optimisation methods
12:44 Hybrid systems with discontinuity in time evolution
14:17 Example: bouncing ball



Popraw.

Simulating Chemical Kinetics with ReactionMechanismSimulator.jl | Matthew S. Johnson | JuliaCon 2021, https://www.youtube.com/watch?v=Bvs-sUK693U

19:35 18:36 RMS' unique tools: symbolic reduction -> 19:35 18:36 RMS' unique tools: symbolic reduction

23:05 Why is paper worth development in Cantera is 1-2 day job in ReactionMechanismSimulator.jl? -> 23:05 Why paper worth


JuliaCon 2017 | The State of the Type System | Jeff Bezanson, https://www.youtube.com/watch?v=Z2LtJUe1q8c

28:36 Possible future type system features -> 28:36 Possible future of the type system features




_Numerical Optimization in Julia_, [https://www.youtube.com/watch?v=O1icUP6sajU](https://www.youtube.com/watch?v=O1icUP6sajU)

Miles Lubin, Iain Dunning, _Numerical Optimization in Julia_, [https://www.youtube.com/watch?v=O1icUP6sajU](https://www.youtube.com/watch?v=O1icUP6sajU)

When someone ask question, volume was quite low, so I could make a lot of mistakes.

00:00 What is Linear Programming (LP)?
01:23 Modeling languages for Linear Programming
03:05 Question: can you use more vector-like notation in AMPL?
03:35 Statements in AMPL can be more complicated that one show now
03:50 Short summary of current state of languages for LP
04:00 Modeling in Julia
04:53 Julia macros allow us to generate fast code
06:58 Question: what are you benchmarked in this example?
07:20 Question: does this macro takes expression and generated actual matrix?
07:52 Question: is writing a file procedure the reason that Julia is slower than AMPL?
08:50 Question: can you run this example asynchronously?
09:06 Question: how much times is take to solve actually LP problem?
09:55 Question: dose language for solving LP problems always use this type of interface?
10:35 Question: what is the external representations of the input?
11:09 Question: what are **Model** and **Variable** functions doing?
11:36 **Variable** functions and operator overloading
12:09 Question: dumb variables in presented problem
13:47 "The whole reason that language as AMPL exists, is that people like to think about it that way"
14:31 Algorithms for solving LP problems
15:04 Question: is this your PhD thesis?
15:25 Question: what happens to different implementations of Dantzig’s simplex algorithm
16:04 Question: what is the name of this thesis?
16:15 Computational and algorithmic challenges in LP
17:02 Simple benchmarks for solving LP problems
18:12 Comments on bounds checking of arrays in Julia
18:24 Results of benchmarks
18:40 Comments on cost of features from higher-level languages
18:57 Question: does Python implementations use numpy?
19:07 Comments on sparse matrix and vectors in Python
19:36 Question: do you write your own code in Julia for this task?
21:12 Question: do you know sparsity pattern before starting the calculation?
21:39 Question: would someone use aforementioned PhD thesis to implement Dantzig’s simplex algorithm in Julia?
22:00 "Not factor of 2 left untouched"
22:36 "Nothing special is happening in this code"
22:53 Fuzzed dot operator inside a loop
23:56 Overview of tutorial, that is mostly unrelated to LP



_Fast Fourier Transforms in Julia_, [https://www.youtube.com/watch?v=1iBLaHGL1AM](https://www.youtube.com/watch?v=1iBLaHGL1AM)

_Statistical Models in Julia_, [https://www.youtube.com/watch?v=v9Io-p_iymI](https://www.youtube.com/watch?v=v9Io-p_iymI)

_Data Analysis in Julia with Data Frames_, [https://www.youtube.com/watch?v=XRClA5YLiIc](https://www.youtube.com/watch?v=XRClA5YLiIc)

_Networking in Julia_, [https://www.youtube.com/watch?v=qYjHYTn7r2w](https://www.youtube.com/watch?v=qYjHYTn7r2w)

_Julia Lightning Round_, [https://www.youtube.com/watch?v=37L1OMk_3FU](https://www.youtube.com/watch?v=37L1OMk_3FU)






Cambridge Julia Meetup (May 2018)

Shared memory parallelism in Julia with multi-threading, [https://www.youtube.com/watch?v=YdiZa0Y3F3c](https://www.youtube.com/watch?v=YdiZa0Y3F3c)






Julia Lightning Round (Alan Edelman, Viral B. Shah)

_Julia Lightning Round_, [https://www.youtube.com/watch?v=37L1OMk_3FU](https://www.youtube.com/watch?v=37L1OMk_3FU)





TiledViews.jl | Rainer Heintzmann | JuliaCon 2021, [https://www.youtube.com/watch?v=i3LwNFJov5Q](https://www.youtube.com/watch?v=i3LwNFJov5Q)

Another slightly harder video to make. Probably they can be much better.

00:00 Welcome
00:13 What is [TiledViews.jl](https://github.com/bionanoimaging/TiledViews.jl)?
01:14 Reasons for tiling
02:28 Example of tiled data
02:47 Demo: processing a picture
04:44 Demo: smoothing results by using window function
06:20 Demo: function **tiled_processing**
06:46 Challenges of tile-based processing
07:14 Acknowledgements


00:00 Welcome












Fourth portion.

| Video title | Link to video | Video time | Playlist time |
|-------------|---------------|------------|---------------|
| [PuMaS.jl...](https://www.youtube.com/watch?v=KQ4Vtsd9XNw) | [https://www.youtube.com/watch?v=KQ4Vtsd9XNw](https://www.youtube.com/watch?v=KQ4Vtsd9XNw) | 31:55 | 44:44 |
| [Julia powered personalised...](https://www.youtube.com/watch?v=9J54K6HbPNQ) | [https://www.youtube.com/watch?v=9J54K6HbPNQ](https://www.youtube.com/watch?v=9J54K6HbPNQ) | 12:13 | 15:12 |
| [500K - Providing training...](https://www.youtube.com/watch?v=aDXDnTT7cps) | [https://www.youtube.com/watch?v=aDXDnTT7cps](https://www.youtube.com/watch?v=aDXDnTT7cps) | 12:23 | 15:08 |
| [Flux...](https://www.youtube.com/watch?v=R81pmvTP_Ik) | [https://www.youtube.com/watch?v=R81pmvTP_Ik](https://www.youtube.com/watch?v=R81pmvTP_Ik) | 26:20 | 29:51 |
| [Combine ML for...](https://www.youtube.com/watch?v=QBT0wq2WBHE) | [https://www.youtube.com/watch?v=QBT0wq2WBHE](https://www.youtube.com/watch?v=QBT0wq2WBHE) | 9:33 | 16:34 |
| [From Deep Neural...](https://www.youtube.com/watch?v=YVABTDrQ0eQ) | [https://www.youtube.com/watch?v=YVABTDrQ0eQ](https://www.youtube.com/watch?v=YVABTDrQ0eQ) | 10:31 | 11:19 |
| [Whale recognition using...](https://www.youtube.com/watch?v=b7Dk_CPfS6M) | [https://www.youtube.com/watch?v=b7Dk_CPfS6M](https://www.youtube.com/watch?v=b7Dk_CPfS6M) | 9:22 | 10:12 |
| [Estimating Non-Linear...](https://www.youtube.com/watch?v=dFyr8U-SY2M) | [https://www.youtube.com/watch?v=dFyr8U-SY2M](https://www.youtube.com/watch?v=dFyr8U-SY2M) | 28:14 | 30:48 |
| [GSReg.jl...](https://www.youtube.com/watch?v=dBvXZqZRSsc) | [https://www.youtube.com/watch?v=dBvXZqZRSsc](https://www.youtube.com/watch?v=dBvXZqZRSsc) | 13:08 | 14:29 |
| [Fast derivative pricing...](https://www.youtube.com/watch?v=dy7tXk403bM) | [https://www.youtube.com/watch?v=dy7tXk403bM](https://www.youtube.com/watch?v=dy7tXk403bM) | 11:44 | 13:22 |
| [Enhanced String handling...](https://www.youtube.com/watch?v=kWqFRGLdqc4) | [https://www.youtube.com/watch?v=kWqFRGLdqc4](https://www.youtube.com/watch?v=kWqFRGLdqc4) | 15:04 | 21:35 |
| [An introduction to high...](https://www.youtube.com/watch?v=jS9eouMJf_Y) | [https://www.youtube.com/watch?v=jS9eouMJf_Y](https://www.youtube.com/watch?v=jS9eouMJf_Y) | 39:21 | 42:28 |
| [For Loops 2.0...](https://www.youtube.com/watch?v=Rp7sTl9oPNI) | [https://www.youtube.com/watch?v=Rp7sTl9oPNI](https://www.youtube.com/watch?v=Rp7sTl9oPNI) | 32:28 | 51:39 |
| [Hierarchical Tensor...](https://www.youtube.com/watch?v=8QGo98705jY) | [https://www.youtube.com/watch?v=8QGo98705jY](https://www.youtube.com/watch?v=8QGo98705jY) | 12:31 | 14:26 |
| [The JuliaGraphs ecosystem...](https://www.youtube.com/watch?v=OZuQoxTPoyM) | [https://www.youtube.com/watch?v=OZuQoxTPoyM](https://www.youtube.com/watch?v=OZuQoxTPoyM) | 13:51 | 15:35 |
| [EvolvingGraphs.jl...](https://www.youtube.com/watch?v=qo25P5TURuw) | [https://www.youtube.com/watch?v=qo25P5TURuw](https://www.youtube.com/watch?v=qo25P5TURuw) | 13:47 | 15:45 |
| [Solving Partial Differential...](https://www.youtube.com/watch?v=okGybBmihOE) | [https://www.youtube.com/watch?v=okGybBmihOE](https://www.youtube.com/watch?v=okGybBmihOE) | 1:48:53 | 1:57:26 |
| [Queryverse](https://www.youtube.com/watch?v=2oXSA2w-p28) | [https://www.youtube.com/watch?v=2oXSA2w-p28](https://www.youtube.com/watch?v=2oXSA2w-p28) | 2:07:48 | 2:18:32 |
| [A practical introduction...](https://www.youtube.com/watch?v=SeqAQHKLNj4) | [https://www.youtube.com/watch?v=SeqAQHKLNj4](https://www.youtube.com/watch?v=SeqAQHKLNj4) | 2:09:09 | 2:15:15 |
| [Natural Language Processing...](https://www.youtube.com/watch?v=f7RNuOLDyM8) | [https://www.youtube.com/watch?v=f7RNuOLDyM8](https://www.youtube.com/watch?v=f7RNuOLDyM8) | 1:32:09 | 1:34:29 |


The last portion.

| Video title | Link to video | Video time | Playlist time |
|-------------|---------------|------------|---------------|
| [Numerical Analysis in Julia](https://www.youtube.com/watch?v=MAhLlLOxWGg) | [https://www.youtube.com/watch?v=MAhLlLOxWGg](https://www.youtube.com/watch?v=MAhLlLOxWGg) | 2:06:52 | 2:15:23 |
| [Julia apps on...](https://www.youtube.com/watch?v=kSp6d3qSb3I) | [https://www.youtube.com/watch?v=kSp6d3qSb3I](https://www.youtube.com/watch?v=kSp6d3qSb3I) | 33:03 | 38:51 |
| [Julia for Physics...](https://www.youtube.com/watch?v=BmVd7pw6Trc) | [https://www.youtube.com/watch?v=BmVd7pw6Trc](https://www.youtube.com/watch?v=BmVd7pw6Trc) | 16:22 | 19:26 |
| [Native Elementary Functions...](https://www.youtube.com/watch?v=B03F6EFUm78) | [https://www.youtube.com/watch?v=B03F6EFUm78](https://www.youtube.com/watch?v=B03F6EFUm78) | 14:32 | 20:03 |
| [Atomistic simulation...](https://www.youtube.com/watch?v=Kbrj4EZbGWs) | [https://www.youtube.com/watch?v=Kbrj4EZbGWs](https://www.youtube.com/watch?v=Kbrj4EZbGWs) | 11:36 | 30:12 |
| [Simulating global...](https://www.youtube.com/watch?v=EahBURR9b1U) | [https://www.youtube.com/watch?v=EahBURR9b1U](https://www.youtube.com/watch?v=EahBURR9b1U) | 26:03 | 27:09 |
| [Learnings from scaling Julia up...](https://www.youtube.com/watch?v=9I2SBKGOfS4) | [https://www.youtube.com/watch?v=9I2SBKGOfS4](https://www.youtube.com/watch?v=9I2SBKGOfS4) | 13:11 | 13:47 |



































































JuliaCon 2017 | Cows, Lakes, and a JuMP extension ... | Oscar Dowson

_Cows, Lakes, and a JuMP extension..._, [https://www.youtube.com/watch?v=LDgNmsOCl1A](https://www.youtube.com/watch?v=LDgNmsOCl1A)

00:00 Welcome!
00:10 What cows have to do with Julia?
00:36 Julia meats Daisy in the filed of multi-stage stochastic optimisation
00:51 New Zealand dairy farm on which I grew up
01:48 Hydro-thermal scheduling problem
03:10 [MOO](https://github.com/odow/MOO): The Milk Output Optimizer
04:22 Stochastic Dual Dynamic Programming (SDDP)
04:51 Problem with solving SDDP problems with standard languages
05:18 Why not do it in Julia? Lot of people had this idea
05:35 Moa.jl: Multi-stage Optimisation Application
06:29 Moa.jl is quite good
07:14 Takeaway thoughts
07:38 Obligatory pictures of cows










Interesting YT videos on numerical methods

After watching, in my humble opinion, wonderful Nick Highman's keynote talk from JuliaCon 2018 [_Tricks and Tips in Numerical Computing_](https://www.youtube.com/watch?v=Q9OLOqEhc64), I found on YT more talks and lectures by him. Probably there are more people like me in Julia community, interested in numerical computing but still at the begin of they journey in this filed. I believe that may also can find them useful and enlightening, so I decided to put some links to them here. I hope that I'm not totally wrong in thinking that.

Nick Highman, [_Probabilistic Versus Worst-Case Rounding Error Analysis_](https://www.youtube.com/watch?v=-1hVnDo4qzw)
Nick Highman, [_Solving Dense Linear Systems: A Brief History and Future Directions_](https://www.youtube.com/watch?v=xSES0VrCRbc), 2021










































































































JuliaCon 2019 | Raising Diversity & Inclusion among Julia users

_Raising Diversity & Inclusion among Julia users_, [https://www.youtube.com/watch?v=9cedY6zyo8I](https://www.youtube.com/watch?v=9cedY6zyo8I)

00:00 Welcome!
01:24 Julia Diversity and Inclusion Grant
01:53 Outline of the talk






How much do you need to know about compiler to work on Julia math stdlib?










I'm not sure that I used words "parallel" and "parallelism" in correct way. Someone should check that.

00:00 Welcome!
00:28 Why we need threads?
01:37 Task parallelism
02:43 Data parallelism
03:35 Julia's experimental threading infrastructure added in 2015/2016
04:35 Successes of aforementioned threading infrastructure
05:35 What we've learned
06:25 Problem is not adding threads to Julia, but making them useful at every level
06:59 Nested parallelism: parallel code calling function from library that is also parallel
08:18 Example: multiplying two n x n matrices
09:29 Example: running code sequentially
10:10 Example: you need O(n^2) space
10:27 Example: running code in parallel on 4 cores with OpenMP with OMP_NESTED = 1
11:26 Example: such parallel code need O(n^3) in space
11:37 Another way: work stealing
12:47 Problem: work stealing algorithm essentially run like serial algorithm
13:57 Parallel depth-first scheluding
15:52 **partr** -- parallel task runtime
17:15 **partr** implementation
18:30 **partr** -- priority queues
21:23 **partr** -- handling nested parallelism
23:22 Possible problem: we not synchronize at each spawn point
24:13 Why all these things are important?
24:59 Q&A: is Julia more suitable for implementation of **partr** than other languages?

Shared memory parallelism in Julia with multi-threading | Kiran Pamnany | Cambridge Julia Meetup (May 2018), [https://www.youtube.com/watch?v=YdiZa0Y3F3c](https://www.youtube.com/watch?v=YdiZa0Y3F3c)

This talk is now 26:33 long, but it would be nice to cut it around 25:52. You can look at proposed timestamps [here](https://github.com/JuliaCommunity/YouTubeVideoTimestamps/issues/151).


My version of your work.

Contents
00:00, 0. Opening and introduction
00:48, 1. Overview
02:20, 2. Prelude, compressed sensing
04:53, 3. Singular Value Decomposition, recap
06:27, 4. MRI reconstruction, general idea
07:32, 5. Original Image
08:20, 6. Singular Value Thresholding (SVT) for MRI Applications
09:16, 7. SVT Image
10:37, 8. Blocked SVT for MRI Applications
12:02, 9. Blocked SVT Image
12:34, 10. What about Mixing and Matching?
13:11, 11. Original JPEG(left image) vs Blocked SVT JPEG (right image)
13:29, 12. Anisotropic Total Variation (TV) Denoising Goldstein and Osher
16:26, 13. Isotropic TV Denosing Goldstein and Osher
17:21, 14. Reflection
17:48, 15. MRICompress.jl
18:53, 16. Data Flow
19:39, 17. Deployment
20:10, 18. Project Dependencies
20:53, 19. Yet to cover many other methods
22:24, 20. References
23:00, 21. Q&A


Can you check my version of your work?

Contents
00:00, 0. Opening and introduction
00:42, 1. Begin of the lecture
01:31, 2. Who am I?
02:03, 3. Introduction to Amazon Braket
02:40, 3.1. Amazon Braket - the AWS quantum computing service
03:21, 3.2. Architecture of the service
04:31, 3.3. Available Quantum Devices
05:25, 3.4. Local and on-demand simulators
05:51, 3.5. High level view of Braket SDK components
07:48, 4. Introducing Braket.jl
07:57, 4.1. An experimental Julia SDK for Amazon Braket
09:42, 4.2. Building and running gate-based circuits
11:16, 4.3. Building and running analog Hamiltonian simulations
12:23, 4.4. Running dedicated "jobs" - end to end experiments
13:51, 5. How can you get involved?
14:12, 5.1. Integrating with other Julia packages
17:00, 5.2. We are looking foer contributors!
19:02, 5.3. Academic research & open source credits
20:52, 6. Come work with us at the Saturday hackathon!
21:17, 6.1. Where do we go from here?
23:29, 7. Q&A

I tweaked your work a bit.

Contents
00:00, 0. Opening and introduction
00:29, 1. A chat at ROADEF in Feb 2016
01:34, 2. Lecturing with Julia and JuMP (1st Course)
04:00, 3. Short Survey on 3 aspects: student - Julia - JuMP
06:50, 4. Lecturing with Julia and JuMP (2nd Course)
07:48, 5. Short Survey on 3 aspects: student - Julia+MOA
09:18, 6. Conclusion

I tweaked it a bit.

Contents
00:00, 0. Introduction
00:33, 1. Unapologetically Beyond Universality
01:29, 2. WHEN THE MAN COMES AROUND...
03:00, 3. Universality in random matrix theory and beyond
04:45, 4. Why beyond universality?
06:07, 5. Determinantal expansions
07:30, 6. Numerical evaluation
09:07, 7. Extreme integrability
12:42, 8. The case beta = 2
15:46, 9. Reverse engineering shinault-tracy
18:19, 10. Integration, literally so
20:46, 11. Example
21:31, 12. Linear form structure of the u_jk-minors
22:48, 13. Example
23:48, 14. Application: solution of Ulam's problem
26:01, 15. About tricks
28:13, Q&A

Contents
00:00, 0. Opening
00:53, 1. Introduction
00:54, 1.1. Nolinear nonconvex optimization
01:29, 1.2. JuliaSmoothOptimizers: Brief genesis
02:49, 1.3. Some stats...
03:29, 1.4. JSO: The environment
04:07, 1.5. JSOSuite: Motivations
05:15, 1.6. Code example
05:56, 2. Modeling
05:57, 2.1. NLPModels API
07:16, 2.2. Access derivatives
07:59, 2.3. Implement the API
09:30, 2.4. NLPModels: Things I won't talk about
10:55, 2.5. ADMLPModels
12:15, 2.6. Example with ADNLPModels backends
13:29, 2.7. Example of test sets: OptimizationProblems.jl
14:48, 2.8. Benchmark with JuMP: Performance profile with grad!
15:27, 2.9. Illustration of mixed NLPModels with ADNLPModels.jl
17:21, 3. Solvers
17:22, 3.1. JSO-compliant optimization solvers
18:13, 3.2. Optimization solvers within JSO
19:44, 3.3. Optimization solvers within JSO: Select solvers
20:24, 3.4. JSOSuite.jl: Solve
20:53, 3.5. JSOSuite.jl: In-place solve!
22:35, 3.6. JSOSuite.jl: Benchmarking
23:04, 3.7. Benchmark CUTEst equality
23:22, 3.8. Benchmark CUTEst: DEI-Idl vs Knitro vs Ipopt
24:35, 3.9. JSOSuite.jl: Multi-precision solvers RipQP
25:33, 4. Conclusion
26:32, 5. Q&A



My rework of what you have done.

Contents
00:00, 0. Opening
00:53, 1. Introduction
00:54, 1.1. Nolinear nonconvex optimization
01:29, 1.2. JuliaSmoothOptimizers:Brief genesis
02:49, 1.3. Some stats...
03:29, 1.4. JSO: The environment
04:07, 1.5. JSOSuite: Motivations
05:15, 1.6. Code example
05:56, 2. Modeling
05:57, 2.1. NLPModels API
07:16, 2.2. Access derivatives
07:59, 2.3. Implement the API
09:30, 2.4. NLPModels: Things I won't talk about
10:55, 2.5. ADMLPModels
12:15, 2.6. Example with ADNLPModels backends
13:29, 2.7. Example of test sets: OptimizationProblems.jl
14:48, 2.8. Benchmark with JuMP: Performance profile with grad!
15:27, 2.9. Illustration of mixed NLPModels with ADNLPModels.jl
17:21, 3. Solvers
17:22, 3.1. JSO-compliant optimization solvers
18:13, 3.2. Optimization solvers within JSO
19:44, 3.3. Optimization solvers within JSO: Select solvers
20:24, 3.4. JSOSuite.jl: Solve
20:53, 3.5. JSOSuite.jl: In-place solve!
22:35, 3.6. JSOSuite.jl: Benchmarking
23:04, 3.7. Benchmark CUTEst equality
23:22, 3.8. Benchmark CUTEst: DEI-Idl vs Knitro vs Ipopt
24:35, 3.9. JSOSuite.jl: Multi-precision solvers RipQP
25:33, 4. Conclusion
26:32, 5. Q&A

I allowed myself to make few channegs to what you did.

Contents
00:00 Introduction
01:32 1) Highlights of Julia. Interactivity
03:42 Speed
04:39 Expressivity
05:51 Onboarding newcomers
07:08 2) New features. Overview and history
08:59 Latency and load times
14:32 Package extensions
17:38 Independence of Stdlibs from base Julia
19:00 JuliaSyntax.jl
21:00 REPL improvements
22:46 Other language highlights
23:34 Improved debugging & profiler tools
26:38 Stacktrace rendering
28:00 Static compilation
35:05 GPU ecosystem & accelerated computing
37:32 Threading
38:07 Garbage collection
39:00 Ecosystem highlights
39:43 Parallel efficiency (ImplicitGlobalGrid.jl)
40:19 Black hole imaging (w/ Julia & Enzyme.jl)
42:03 Begining of Q&A
42:08 Q&A: precompilation (time & profiling)
43:03 Q&A next LTS
44:03 Q&A: documentation, testing & macro hygiene
46:00 Q&A: independence of Stdlibs
46:50 Q&A: on debugger usage difficulty
49:35 Q&A: comment on cormullion's art

Contents
00:00 Welcome
00:06 Introduction
00:27 What is Dagger.jl?
02:10 What is DTables.jl
03:50 DTables: Out of core data
06:30 DTables: Data partitionning
11:20 Dagger: Lazy operations
12:52 DTables: Caveat with GC (CSV < Arrow)
14:07 DTables: Examples
17:43 DTables: Heterogeneous tables support
20:12 Dagger: Supported data formats
21:49 Dagger: Chunks and data on disk
22:40 Conclusion
23:13 Questions

Resources
Code from the talk, [link](https://github.com/jpsamaroo/JuliaCon2023Talks/tree/main/Data).

A little bit tweaked version of your work.

Contents
00:00 Opening and introduction
01:17 Creating a DataFrame from a CSV file
01:54 Mutating a DataFrame to sort its rows
03:44 Visualizing data using a regression and plotting
04:22 Comments on DataFrames' pace of development
08:44 DataFrames' evolution, what has changed since last JuliaCon?
09:05 Breaking changes
11:42 New functionalities
16:29 On the "Jula for Data Analysis" book
17:49 Perspectives
18:42 Conclusion
19:00 Questions

I allowed myself to tweak your work.

Contents
00:00 Intro
02:54 Import data
04:20 Violin plots
09:37 Histograms and bar charts
14:32 Insets
15:47 Error bars
20:37 Double axes
23:33 High dimensional data in 2D
28:29 Outro

I tweaked it a bit.

Contents
00:00, 0. Introduction
01:04, 1. What is Bayesian Inference
03:21, 2. Scalable, Reactive, and Efficient
05:50, 3. What can you do with RxInfer
06:04, 3.1. Continual Inference in Non-Linear Dynamical Systems with Infinite Data Streams
07:14, 3.2. Real-time Reactive Decision Making With Sctive Inference
08:46, 3.3. Smart Naviation and Collision Sboidance
09:50, 3.4. Adaptive Audio Source Separation
11:03, 3.5. Efficient Inference on Low-Power devices without GPU
12:58, 3.6. Other Examples
14:45, 4. Architecture And Design Principles
14:50, 4.1. Reactive Programming
16:09, 4.2. Computational Factor Graphs
17:37, 4.3. Reactive Message Passing
20:33, 5. How Does RxInfer compare to Turing
22:28, 6. Overview


I tweaked your work a bit.

Contents
00:00, 0. Introduction
00:37, 1. Potential insurance analytics applications
01:19, 1.1. Use case 1 - Similarity calculation
02:09, 1.2. Use case 2 - Simulation
02:31, 1.3. Use case 3 - Parameter estimation
03:34, 2.1. Use case 1 - Similarity calculation (Categorical)
04:27, 2.2. Use case 2 - Simulation (Variable Setup)
05:44, 2.3. Use case 3 - Parameter estimation
06:50, 3. Future work

Contents
00:00 Intro
01:43 Basic operations and types
09:55 Backslash operator
11:50 Factorizations
18:24 Sparse linear algebra
21:34 Images as matrices
34:40 Outro

















Wzorcowa forma opisu. Złożone z opisu kilku różnych wystąpień.

JuliaCon 2017 | A Superfacility Model for Data-Intensive Science | Kathy Yelick

[_A Superfacility Model for Data-Intensive Science_](https://www.youtube.com/watch?v=IEfQ5jIQB4Y),


Contents
00:06 Introduction
00:21 Talk outline
00:45 What is JuMP?
01:28 Example JuMP code
02:48 The zoo of modeling languages
03:30 Why is JuMP interesting?
07:03 What is JuMP used for?
12:50 Case study: PSR
14:14 JuMP as a framework
15:43 JuMP 1.0 and how we got here
20:41 What you need to know
22:21 What's next
22:54 Thank you!

Resources
AD4SM.jl package [repository](https://github.com/avigliotti/AD4SM.jl).
JuMP [repository](https://github.com/jump-dev/JuMP.jl/).
JuMP [documentation](https://jump.dev/JuMP.jl/stable/).
